---
title: Coding For Good
date: 2016-10-08 20:55 UTC
author: Paul Scarrone
category: education
tags: software, morality, social-impact
---

Recently, I was listening to the [Ruby Rogues Podcast Episode 278](https://devchat.tv/ruby-rogues/278-rr-consequences-of-an-insightful-algorithm-with-carina-c-zona)
and learning about a talk that Carina C Zona gave at Ruby Conf 2015 entitled __Consequences of an Insightful Algorithm__ which drew me back to my college days at Saint Vincent College, in lovely Latrobe, Pennsylvania, a Catholic college whose Computer Science Department was lead by a Benedictine monk. If you are unfamiliar with the Benedictine tradition consider a highly academic, philosophical, and ethically focused group of men who, like the Franciscans, had taken a vow of poverty.

It was through this focus on ethics that a constant discussion across all classes was that of software ethics. How we each can impact the world with the power that this new science of Computer Science could hold. Since that time I have concerned myself with business ethics and general morality as the guideposts for my actions. The positive social impact of software seemed self-evident in my involvement with the Open Source Software movement. I was building things that would help others and thus it was good.

Carina explained that good intentions was not the only indicator of moral software through some real word examples where the casual existence of developer bias hurt others.

Please watch her talk and listen to the RR episode.

<div style="max-width: 50%; margin:auto;"><iframe width="560" height="315" src="https://www.youtube.com/embed/Vpr-xDmA2G4" frameborder="0" allowfullscreen></iframe></div>

As a web developer I am directly responsible for how content is delivered in a visual and interactive way. I am white, male, possess average visual acuity and am not color blind. Every day I look at a website this is my example of my audience, but it is also my responsibility to consider the things I am not. Its not a matter of inclusion or politically correctness, but a matter of empathy and consideration. I need to look at my websites with a screen reader and still be able to navigate it easily or check my color palate with a color blind filter.

As a software engineer I care about if someone else can read my code and understand it. We call it teamwork and best practice, so why not have the same consideration for our users. We have to be honest about who we are and where we came from to define our native bias. Bias like stereotypes are not by themselves evil its when we make expectations of others based upon these factors that we can do harm. I would never want to be so foolish as to believe that I can live my life without bias. What I can do is flag my bias and remember they don't define others.

In particular was the story about the web-cam that did facial recognition but could not see people with a dark complexion. I have sympathy for the engineers because I could see myself in this situation. Building a device and software around a basic premise and using the materials at hand to test the technology. I would not be surprised if the developers were predominately white and male. There was a deadline and a shipping date and if I have learned anything about projects. They will take exactly as long as they are given to finish. No one is thinking about a focus group or a beta test group and the product ships. Now you find out it only works for white people...and it all seems so simple in retrospect but as Carina mentions the damage has been done.

So learn from the mistakes of huge complex companies that didn't know better and consider what your product looks like to someone not in your condition. Consider what you write and how someone from a different background or gender might interpret it.

Software ethics means use empathy in your choices and you will end up Coding for Good.
